{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8909493,"sourceType":"datasetVersion","datasetId":5357078},{"sourceId":473190,"sourceType":"modelInstanceVersion","modelInstanceId":381140,"modelId":400838}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        # print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:39:24.716892Z","iopub.execute_input":"2025-07-17T05:39:24.717159Z","iopub.status.idle":"2025-07-17T05:39:26.367655Z","shell.execute_reply.started":"2025-07-17T05:39:24.71714Z","shell.execute_reply":"2025-07-17T05:39:26.366863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport pandas as pd\n\nimport copy\nimport torch\nimport torch.nn as nn\nfrom PIL import Image\nimport torch.optim as optim\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F\nfrom ipywidgets import FileUpload\nimport torchvision.transforms as T\nfrom IPython.display import display\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nfrom torchvision.io import read_image\nfrom torchvision.datasets import ImageFolder","metadata":{"execution":{"iopub.status.busy":"2025-07-17T05:52:48.233231Z","iopub.execute_input":"2025-07-17T05:52:48.23349Z","iopub.status.idle":"2025-07-17T05:52:48.238626Z","shell.execute_reply.started":"2025-07-17T05:52:48.233471Z","shell.execute_reply":"2025-07-17T05:52:48.237886Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split\n\n# Directory (single folder for all data)\ndata_dir = \"/kaggle/input/pumpkin-leaf-diseases-dataset-from-bangladesh/Pumpkin Leaf Diseases Dataset From Bangladesh/Original Dataset\"\n\n# Transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(30),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n])\n\n# Load full dataset from one folder\nfull_dataset = ImageFolder(data_dir, transform=transform)\n\n# Split into train and validation sets (80/20)\ntrain_size = int(0.75 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:39:27.249738Z","iopub.execute_input":"2025-07-17T05:39:27.250379Z","iopub.status.idle":"2025-07-17T05:39:27.279588Z","shell.execute_reply.started":"2025-07-17T05:39:27.250353Z","shell.execute_reply":"2025-07-17T05:39:27.278899Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# torch.cuda.is_available()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:39:27.566436Z","iopub.execute_input":"2025-07-17T05:39:27.567175Z","iopub.status.idle":"2025-07-17T05:39:27.570319Z","shell.execute_reply.started":"2025-07-17T05:39:27.567151Z","shell.execute_reply":"2025-07-17T05:39:27.569651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AlexNet_simplified(nn.Module):\n    def __init__(self, num_classes=9, exit_threshold=0.90):\n        super(AlexNet_simplified, self).__init__()\n        self.exit_threshold = exit_threshold\n\n        # Conv Layer 1\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n            nn.BatchNorm2d(96),\n            nn.ReLU(),\n            nn.MaxPool2d(3, 2)\n        )\n\n        # Conv Layer 2\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(3, 2)\n        )\n\n        self.exit1 = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(256, num_classes)\n        )\n\n        # Conv Layer 3\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n            nn.BatchNorm2d(384),\n            nn.ReLU()\n        )\n\n        self.exit2 = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(384, num_classes)\n        )\n\n        # Conv Layer 4\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n            nn.BatchNorm2d(384),\n            nn.ReLU()\n        )\n\n        self.exit3 = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(384, num_classes)\n        )\n\n        # Conv Layer 5\n        self.conv5 = nn.Sequential(\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2)\n        )\n\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        \n        # Final Classifier\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(4096, num_classes)\n        )\n\n    def forward(self, x, inference=False):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        out1 = self.exit1(x)\n\n        x = self.conv3(x)\n        out2 = self.exit2(x)\n\n        x = self.conv4(x)\n        out3 = self.exit3(x)\n\n        x = self.conv5(x)\n        out_final = self.classifier(x)\n\n        if inference:\n            conf1 = F.softmax(out1, dim=1).max(1).values\n            if conf1.item() >= self.exit_threshold:\n                return out1, \"Exit1\"\n\n            conf2 = F.softmax(out2, dim=1).max(1).values\n            if conf2.item() >= self.exit_threshold:\n                return out2, \"Exit2\"\n\n            conf3 = F.softmax(out3, dim=1).max(1).values\n            if conf3.item() >= self.exit_threshold:\n                return out3, \"Exit3\"\n\n            return out_final, \"Final\"\n\n        # During training, return all outputs\n        return out1, out2, out3, out_final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:39:27.817627Z","iopub.execute_input":"2025-07-17T05:39:27.818042Z","iopub.status.idle":"2025-07-17T05:39:27.829054Z","shell.execute_reply.started":"2025-07-17T05:39:27.818017Z","shell.execute_reply":"2025-07-17T05:39:27.828307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = AlexNet_simplified(num_classes=5,exit_threshold=0.8).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.1, patience=2, verbose=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:39:32.282426Z","iopub.execute_input":"2025-07-17T05:39:32.283115Z","iopub.status.idle":"2025-07-17T05:39:33.06516Z","shell.execute_reply.started":"2025-07-17T05:39:32.283081Z","shell.execute_reply":"2025-07-17T05:39:33.064309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_accuracies = []\nval_accuracies = []\ntrain_losses = []\nval_losses = []\n\nnum_epochs = 30\npatience = 5\nbest_val_acc = 0\nearly_stop_counter = 0\nbest_model_wts = copy.deepcopy(model.state_dict())\n\n# Set weights for losses\nŒ±1, Œ±2, Œ±3, Œ±4 = 0.2, 0.2, 0.2, 0.4  # You can tune this\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss, train_correct = 0, 0\n\n    for images, labels in tqdm(train_loader, desc=\"training loop\"):\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        out1, out2, out3, out_final = model(images, inference=False)\n\n        # Individual losses\n        loss1 = criterion(out1, labels)\n        loss2 = criterion(out2, labels)\n        loss3 = criterion(out3, labels)\n        loss_final = criterion(out_final, labels)\n\n        # Combined weighted loss\n        loss = Œ±1 * loss1 + Œ±2 * loss2 + Œ±3 * loss3 + Œ±4 * loss_final\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item() * images.size(0)\n        train_correct += (out_final.argmax(1) == labels).sum().item()\n\n    train_loss /= len(train_loader.dataset)\n    train_acc = train_correct / len(train_loader.dataset)\n\n\n    # Validation\n    model.eval()\n    val_loss, val_correct = 0, 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"validation loop\"):\n            images, labels = images.to(device), labels.to(device)\n            _, _, _, outputs = model(images, inference=False)\n            loss = criterion(outputs, labels)\n    \n            val_loss += loss.item() * images.size(0)\n            val_correct += (outputs.argmax(1) == labels).sum().item()\n            \n    val_loss /= len(val_loader.dataset)\n    val_acc = val_correct / len(val_loader.dataset)\n\n    train_accuracies.append(train_acc)\n    val_accuracies.append(val_acc)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n\n    scheduler.step(val_loss)\n\n    print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val Loss: {val_loss:.4f}\")\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        best_model_wts = copy.deepcopy(model.state_dict())\n        early_stop_counter = 0\n    else:\n        early_stop_counter += 1\n        if early_stop_counter >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\nmodel.load_state_dict(best_model_wts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:39:33.066403Z","iopub.execute_input":"2025-07-17T05:39:33.06703Z","iopub.status.idle":"2025-07-17T05:50:18.893557Z","shell.execute_reply.started":"2025-07-17T05:39:33.067011Z","shell.execute_reply":"2025-07-17T05:50:18.892983Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = AlexNet_simplified(num_classes=5).to(device)\n# model.load_state_dict(torch.load(\"/kaggle/input/alexnet_simplified/pytorch/simpler/1/alexnet_simplified_ee1_0.5_30.pth\", map_location=device))\n# model.eval()\n\n# exit_counts = {\"Exit1\": 0, \"Exit2\": 0, \"Exit3\": 0, \"Final\": 0}\n# correct = 0\n# total = 0\n\n# with torch.no_grad():\n#     for images, labels in tqdm(val_loader, desc=\"early exit inference\"):\n#         images, labels = images.to(device), labels.to(device)\n#         for i in range(images.size(0)):\n#             img = images[i].unsqueeze(0)  # (1, 3, H, W)\n#             label = labels[i].unsqueeze(0)\n#             output, exit_name = model(img, inference=True)\n#             pred = torch.argmax(output, dim=1)\n\n#             # Print prediction and exit point (exclude final if you want)\n#             if exit_name != \"Final\":\n#                 print(f\"Predicted: {pred.item()} | Exited at {exit_name}\")\n\n#             correct += (pred == label).sum().item()\n#             total += 1\n#             exit_counts[exit_name] += 1\n\n# print(f\"\\n‚úÖ Early Exit Accuracy: {correct/total:.4f}\")\n# print(f\"üìä Exit Distribution: {exit_counts}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\n\nexit_counts = {\"Exit1\": 0, \"Exit2\": 0, \"Exit3\": 0, \"Final\": 0}\ncorrect = correct1 = correct2 = correct3 = correct4 = 0\nwrong1 = wrong2 = wrong3 = wrong4 = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in tqdm(val_loader, desc=\"early exit inference\"):\n        images, labels = images.to(device), labels.to(device)\n        for i in range(images.size(0)):\n            img = images[i].unsqueeze(0)  # (1, 3, H, W)\n            label = labels[i].unsqueeze(0)\n            output, exit_name = model(img, inference=True)\n            pred = torch.argmax(output, dim=1)\n\n            # Print prediction and exit point (exclude final if you want)\n            # if exit_name != \"Final\":\n            #     print(f\"Predicted: {pred.item()} | Exited at {exit_name}\")\n\n            if exit_name == \"Exit1\":\n                if pred == label:\n                    correct1 += 1\n\n            if exit_name == \"Exit2\":\n                if pred == label:\n                    correct2 += 1\n\n            if exit_name == \"Exit3\":\n                if pred == label:\n                    correct3 += 1\n\n            if exit_name == \"Final\":\n                if pred == label:\n                    correct4 += 1\n                \n            correct += (pred == label).sum().item()\n            total += 1\n            exit_counts[exit_name] += 1\n\nprint(\"Pumpkin-0.8-final\")\nprint(f\"\\n‚úÖ Early Exit Accuracy: {correct/total:.4f}\")\nprint(\"\\n‚úÖ Early Exit Block 1 Accuracy: \",correct1/exit_counts[\"Exit1\"])\nprint(\"\\n‚úÖ Early Exit Block 2 Accuracy: \",correct2/exit_counts[\"Exit2\"])\nprint(\"\\n‚úÖ Early Exit Block 3 Accuracy: \",correct3/exit_counts[\"Exit3\"])\nprint(\"\\n‚úÖ Final Early Exit Block Accuracy: \",correct4/exit_counts[\"Final\"])\nprint(f\"\\nüìä Exit Distribution: {exit_counts}\")\n\n# Calculate accuracy percentages\naccuracies = [\n    (correct1 / exit_counts[\"Exit1\"]) * 100,\n    (correct2 / exit_counts[\"Exit2\"]) * 100,\n    (correct3 / exit_counts[\"Exit3\"]) * 100,\n    (correct4 / exit_counts[\"Final\"]) * 100\n]\n\nplt.figure(figsize=(6, 4))\nplt.bar([\"exit_1\", \"exit_2\", \"exit_3\", \"exit_final\"], accuracies, color='skyblue')\nplt.xlabel(\"Exit Points\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Accuracy of Each Block\")\nplt.ylim(0, 100)  # Set y-axis range from 0 to 100\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:50:35.839948Z","iopub.execute_input":"2025-07-17T05:50:35.840491Z","iopub.status.idle":"2025-07-17T05:50:42.187148Z","shell.execute_reply.started":"2025-07-17T05:50:35.840467Z","shell.execute_reply":"2025-07-17T05:50:42.186363Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\nplt.bar([\"wrong\",\"correct\"],[total-correct,correct], color='skyblue')\nplt.xlabel(\"Exit Points\")\nplt.ylabel(\"Number of Samples\")\nplt.title(\"Samples Exiting at Each Point\")\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:51:37.225436Z","iopub.execute_input":"2025-07-17T05:51:37.225821Z","iopub.status.idle":"2025-07-17T05:51:37.379125Z","shell.execute_reply.started":"2025-07-17T05:51:37.225796Z","shell.execute_reply":"2025-07-17T05:51:37.378359Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"exit_counts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:51:35.74294Z","iopub.execute_input":"2025-07-17T05:51:35.743764Z","iopub.status.idle":"2025-07-17T05:51:35.748571Z","shell.execute_reply.started":"2025-07-17T05:51:35.743728Z","shell.execute_reply":"2025-07-17T05:51:35.748014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\nplt.bar(exit_counts.keys(), exit_counts.values(), color='skyblue')\nplt.xlabel(\"Exit Points\")\nplt.ylabel(\"Number of Samples\")\nplt.title(\"Samples Exiting at Each Point\")\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:51:37.640636Z","iopub.execute_input":"2025-07-17T05:51:37.641412Z","iopub.status.idle":"2025-07-17T05:51:37.780756Z","shell.execute_reply.started":"2025-07-17T05:51:37.64139Z","shell.execute_reply":"2025-07-17T05:51:37.780077Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\n\nplt.subplot(1,3,1)\nplt.plot(train_accuracies)\nplt.plot(val_accuracies)\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\n\nplt.subplot(1,3,2)\nplt.plot([x * 100 for x in train_accuracies])\nplt.plot([x * 100 for x in val_accuracies])\nplt.title('Model Accuracy (0‚Äì100%)')\nplt.ylabel('Accuracy (%)')\nplt.xlabel('Epoch')\nplt.ylim(0, 100)\nplt.legend(['Train', 'Val'], loc='upper left')\n\nplt.subplot(1,3,3)\nplt.plot(train_losses)\nplt.plot(val_losses)\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:52:07.208592Z","iopub.execute_input":"2025-07-17T05:52:07.208962Z","iopub.status.idle":"2025-07-17T05:52:07.683439Z","shell.execute_reply.started":"2025-07-17T05:52:07.208938Z","shell.execute_reply":"2025-07-17T05:52:07.682741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the same transform as during training\ninference_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n])\n\n# Load class names from dataset\nclass_names = full_dataset.classes  # Uses ImageFolder\n\ndef predict_image(image_path, model, device, threshold=0.90):\n    # Temporarily override threshold\n    original_threshold = model.exit_threshold\n    model.exit_threshold = threshold\n\n    # Load and preprocess image\n    image = Image.open(image_path).convert(\"RGB\")\n    image_tensor = inference_transform(image).unsqueeze(0).to(device)\n\n    # Inference with early exit\n    model.eval()\n    with torch.no_grad():\n        output, exit_point = model(image_tensor, inference=True)\n        probabilities = F.softmax(output, dim=1)\n        confidence, predicted_class_idx = torch.max(probabilities, 1)\n\n    predicted_class = class_names[predicted_class_idx.item()]\n    confidence_score = confidence.item()\n\n    # Restore original threshold\n    model.exit_threshold = original_threshold\n\n    # Print and plot\n    print(f\"‚úÖ Predicted Class: {predicted_class}\")\n    print(f\"üîÅ Exit Used: {exit_point}\")\n    print(f\"üìà Confidence: {confidence_score:.4f} (Threshold: {threshold})\")\n\n    plt.figure(figsize=(5, 5))\n    plt.imshow(image)\n    plt.axis('off')\n    plt.title(f\"{predicted_class} | {exit_point} | {confidence_score:.2f}\", fontsize=12)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:58:56.785395Z","iopub.execute_input":"2025-07-17T05:58:56.786086Z","iopub.status.idle":"2025-07-17T05:58:56.793803Z","shell.execute_reply.started":"2025-07-17T05:58:56.786051Z","shell.execute_reply":"2025-07-17T05:58:56.793031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example usage\nimage_path = \"/kaggle/input/pumpkin-leaf-diseases-dataset-from-bangladesh/Pumpkin Leaf Diseases Dataset From Bangladesh/Original Dataset/Healthy Leaf/Healthy Leaf (120).jpg\"\npredict_image(image_path, model, device, threshold=0.9)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:01:31.702361Z","iopub.execute_input":"2025-07-17T06:01:31.70294Z","iopub.status.idle":"2025-07-17T06:01:31.886879Z","shell.execute_reply.started":"2025-07-17T06:01:31.702917Z","shell.execute_reply":"2025-07-17T06:01:31.886253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(),\"pumpkin_0.80_final.pth\")\nprint(\"saved\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:01:40.398633Z","iopub.execute_input":"2025-07-17T06:01:40.399185Z","iopub.status.idle":"2025-07-17T06:01:40.878077Z","shell.execute_reply.started":"2025-07-17T06:01:40.399164Z","shell.execute_reply":"2025-07-17T06:01:40.877403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\n\nname = \"pumpkin_0.80_final.pth\"\ntorch.save(model.state_dict(),name)\nFileLink(name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:03:04.997977Z","iopub.execute_input":"2025-07-17T06:03:04.998255Z","iopub.status.idle":"2025-07-17T06:03:05.716186Z","shell.execute_reply.started":"2025-07-17T06:03:04.998236Z","shell.execute_reply":"2025-07-17T06:03:05.715378Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}